# AbstractVoice: AI Integration Quick Reference

**Version 0.4.0+** - Automatic model management with instant TTS setup

## ESSENTIAL SETUP (v0.4.0+)

### ‚ö° Instant TTS
```python
from abstractvoice import VoiceManager

# Initialize - auto-downloads essential model (107MB) if needed
vm = VoiceManager()

# TTS works immediately!
vm.speak("Hello! TTS works out of the box!")
```

### üîß Third-Party API (JSON)
```python
from abstractvoice import list_models, download_model, get_status, is_ready
import json

# Check if ready
ready = is_ready()

# Get models as JSON
models = json.loads(list_models())
french_models = json.loads(list_models('fr'))

# Download specific model
success = download_model('fr.css10_vits')  # Voice ID format
success = download_model('tts_models/de/thorsten/vits')  # Full name

# Get cache status
status = json.loads(get_status())
print(f"Ready: {status['ready_for_offline']}, Models: {status['total_cached']}")
```

### üì¶ Model Management
```python
# Check if essential model is ready
ready = vm.is_model_ready()

# Ensure TTS is ready (downloads if needed)
ready = vm.ensure_ready(auto_download=True)

# List available models with metadata
models = vm.list_available_models()
models_fr = vm.list_available_models('fr')

# Download specific model
success = vm.download_model('de.thorsten_vits')

# Get cache status
status = vm.get_cache_status()
```

## CORE OPERATIONS

### Text-to-Speech
```python
# Basic speech
vm.speak("Hello, I am your AI assistant!")

# Speed control (preserves pitch)
vm.speak("Faster speech", speed=1.5)
vm.speak("Slower speech", speed=0.7)

# With callback
vm.speak("Text", callback=lambda: print("Done"))

# Check state
if vm.is_speaking():
    print("Currently speaking")
```

### Professional Audio Control
```python
# Immediate pause/resume (20ms response)
if vm.pause_speaking():
    print("Paused successfully")

# Resume from exact position
if vm.resume_speaking():
    print("Resumed successfully")

# Check states
if vm.is_speaking(): print("Currently speaking")
if vm.is_paused(): print("Currently paused")

# Stop completely
vm.stop_speaking()
```

### Speech-to-Text & Voice Recognition
```python
def handle_speech(text):
    print(f"User: {text}")
    vm.stop_speaking()  # Stop current speech
    # Replace with your AI processing logic
    response = f"I heard you say: {text}"
    vm.speak(response)

def handle_stop():
    print("User said 'stop'")
    vm.stop_speaking()

# Start listening (blocks until stop command)
vm.listen(on_transcription=handle_speech, on_stop=handle_stop)

# Control listening
if vm.is_listening(): print("Listening active")
vm.stop_listening()
```

### Language & Voice Management
```python
# Language switching
vm.set_language('fr')              # Switch to French
vm.set_language('de')              # Switch to German
current = vm.get_language_name()   # Get current language

# Voice selection
vm.list_voices()                   # List all available voices
vm.list_voices('fr')               # List French voices only
vm.set_voice('fr', 'css10_vits')   # Set specific French voice
vm.set_voice('it', 'mai_male_vits')# Set Italian male voice (0.8x speed)

# Speed control
vm.set_speed(1.2)                  # 20% faster globally
current_speed = vm.get_speed()

# Voice activity detection
vm.change_vad_aggressiveness(2)    # 0-3, higher = more sensitive
```

## VOICE MODES & CLI
```python
# Voice interaction modes
vm.set_voice_mode("full")  # Continuous listening, can interrupt
vm.set_voice_mode("wait")  # Listen only when not speaking
vm.set_voice_mode("stop")  # Stop TTS when user speaks
vm.set_voice_mode("ptt")   # Push-to-talk
```

```bash
# Model management (v0.4.0+)
abstractvoice download-models                    # Download essential model
abstractvoice download-models --language fr     # Download French models
abstractvoice download-models --status          # Check cache status
abstractvoice download-models --all             # Download all models
abstractvoice download-models --clear           # Clear cache

# Voice interface
abstractvoice                      # Voice mode (interactive AI chat)
abstractvoice cli                  # CLI REPL example
abstractvoice web                  # Web API example
abstractvoice simple               # Simple usage demo
abstractvoice check-deps           # Check dependencies
abstractvoice --language fr        # French voice mode
abstractvoice --help               # See all options

# CLI voice commands (in REPL)
/setvoice                          # List all voices with download status
/setvoice fr.css10_vits           # Download and set French voice
/setvoice de.thorsten_vits        # Download and set German voice
```

## AI INTEGRATION PATTERNS

### Streaming AI Responses
```python
def stream_ai_with_voice(user_input, vm):
    # Replace with your streaming AI (OpenAI, Ollama, etc.)
    def mock_ai_stream(text):
        responses = [f"Processing: {text}. ", "Here's my response. ", "Thank you!"]
        for response in responses:
            yield response

    current_sentence = ""
    for chunk in mock_ai_stream(user_input):
        current_sentence += chunk
        # Speak complete sentences immediately
        if chunk.endswith(('.', '!', '?')):
            vm.speak(current_sentence.strip())
            current_sentence = ""

    # Speak any remaining text
    if current_sentence.strip():
        vm.speak(current_sentence.strip())
```

### Complete AI Assistant
```python
from abstractvoice import VoiceManager

class VoiceAI:
    def __init__(self):
        self.vm = VoiceManager(debug_mode=False)
        self.active = False

    def start_conversation(self):
        self.active = True
        self.vm.speak("Hello! How can I help you?")
        self.vm.listen(
            on_transcription=self.handle_input,
            on_stop=self.end_conversation
        )

    def handle_input(self, text):
        if not self.active: return
        self.vm.stop_speaking()  # Stop current speech

        # Your AI processing here
        if "french" in text.lower():
            self.vm.set_language('fr')
            response = "Bonjour! Je parle fran√ßais maintenant."
        else:
            response = f"I heard: {text}. How can I help?"

        if self.active:
            self.vm.speak(response)

    def end_conversation(self):
        self.active = False
        self.vm.speak("Goodbye!")
        self.vm.cleanup()

# Usage
ai = VoiceAI()
ai.start_conversation()
```

## ERROR HANDLING & CLEANUP
```python
# Robust initialization (automatic fallback built-in)
try:
    vm = VoiceManager(debug_mode=False)
    print("‚úÖ Voice system ready")
except Exception as e:
    print(f"‚ö†Ô∏è Voice initialization failed: {e}")
    vm = None

# Safe operations
def safe_speak(vm, text):
    if vm is None:
        return False
    try:
        return vm.speak(text)
    except Exception as e:
        print(f"Speech failed: {e}")
        return False

# Proper cleanup
def cleanup_voice(vm):
    if vm:
        vm.stop_speaking()
        vm.stop_listening()
        vm.cleanup()
```

## QUICK VERIFICATION
```python
# Test your installation
from abstractvoice import VoiceManager

vm = VoiceManager(debug_mode=True)
print(f"‚úÖ Language: {vm.get_language_name()}")
print(f"‚úÖ Supported: {vm.get_supported_languages()}")

# Test basic functionality
vm.speak("Hello! AbstractVoice is working correctly.")
vm.cleanup()
```

## KEY FEATURES FOR AI SYSTEMS

‚úÖ **100% Offline**: Works completely offline after model download (~6GB cache)
‚úÖ **Smart Model Selection**: Automatic VITS ‚Üí Tacotron2 fallback based on system
‚úÖ **Multilingual**: English, French, Spanish, German, Italian (5 languages)
‚úÖ **Voice Selection**: Multiple voices per language with `/setvoice` CLI command
‚úÖ **Professional Audio**: 20ms pause/resume, exact position resume
‚úÖ **Interrupt Handling**: Automatic TTS stop when user speaks
‚úÖ **Speed Control**: Pitch-preserving adjustment (0.5x-2.0x, auto-optimized for Italian)
‚úÖ **Cross-Platform**: macOS, Linux, Windows with universal compatibility
‚úÖ **Voice Modes**: full/wait/stop/ptt for different interaction styles
‚úÖ **Privacy-First**: Zero data transmission, all processing local

## INSTALLATION (v0.3.0+)
```bash
# Recommended: All features
pip install abstractvoice[all]

# Check installation
abstractvoice check-deps

# Test functionality
abstractvoice simple

# Targeted installations
pip install abstractvoice[voice-full]  # Complete voice features
pip install abstractvoice[core-tts]    # TTS only
pip install abstractvoice[core-stt]    # STT only

# For premium voice quality (optional)
# macOS: brew install espeak-ng
# Linux: sudo apt-get install espeak-ng
# Windows: Download espeak-ng-X64.msi
```

## TROUBLESHOOTING (v0.3.0+)
- **Installation issues**: Run `abstractvoice check-deps` for diagnostic report
- **PyTorch conflicts**: Run `pip uninstall torch torchvision torchaudio; pip install abstractvoice[all]`
- **Import errors**: Install missing dependencies with `pip install abstractvoice[voice-full]`
- **Audio issues**: Check `sounddevice.query_devices()` for available devices
- **espeak-ng missing**: VITS models automatically fallback to Tacotron2
- **Voice quality**: Use `vm.list_voices()` to see all available options
- **Debug mode**: Use `VoiceManager(debug_mode=True)` to see model selection

**Quick tests**:
```bash
abstractvoice check-deps              # Comprehensive dependency check
abstractvoice simple                  # Test full functionality
python -c "from abstractvoice import VoiceManager; VoiceManager().speak('Test')"
```
